{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "I have three testing data frames from different reddits.  I can pull in each of them and tune them with the different models by changing which csv file I bring in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./data/space_data.csv')\n",
    "#df = pd.read_csv('./data/combined_data.csv')\n",
    "df = pd.read_csv('./data/entertainment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also threw in a random target to see how the models would compare\n",
    "#rand = np.random.randint(2, size = 1351)\n",
    "#df['target'] = rand\n",
    "#rand.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "It is important that we split the data before we start training our model or create our vectorization.  When applying the model it will have no concept of the word from the original model so the data needs to be split and fit only on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(831,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350180505415162\n",
      "CPU times: user 52.7 s, sys: 224 ms, total: 52.9 s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' : [ 500, 700, 900],\n",
    "    'cvec__ngram_range'  : [(1, 1), (1,2)],\n",
    "    'rf__n_estimators'   : [ 20,22, 24],\n",
    "    'rf__max_depth'      : [ 18,  20, 22]\n",
    "    \n",
    "}\n",
    "pipe1 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('rf',   rf)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe1, param_grid= rf_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9280575539568345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rf__max_depth': 22,\n",
       " 'rf__n_estimators': 22}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model Books : \n",
    "Features 100,  ngram (1,2), stopwords english, max depth 12 estimators 16\n",
    "\n",
    "cross val .941 , test .950  Baseline Accuracy Books .621\n",
    "\n",
    "#### Space:\n",
    "Features 300, ngram 1,1 stopwords english, max depth 20, estimators 22\n",
    "\n",
    "cross val .908, test .902  Baseline Accuracy .500\n",
    "\n",
    "#### Parties: \n",
    "Features 500 ngram 1,1 stopwords none depth 22 estimators 20\n",
    "\n",
    "cross val .709 Test .680  Baseline Accuracy .526\n",
    "\n",
    "#### Random\n",
    "Did not try and fit best models for random\n",
    "cross val .508 Test .512  Baseline accuracy .516"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "et_params = {\n",
    "    'cvec__stop_words'       : ['english', None], \n",
    "    'cvec__max_features'     : [25,50, 75,],\n",
    "    'cvec__ngram_range'      : [(1, 1), (1,2)],\n",
    "    'et__n_estimators'       : [6,8,10], \n",
    "    'et__max_depth'          : [ 20, 22, 24]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927797833935018\n",
      "CPU times: user 33.9 s, sys: 192 ms, total: 34.1 s\n",
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe2 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('et',   et)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe2, param_grid= et_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172661870503597"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 50,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'et__max_depth': 22,\n",
       " 'et__n_estimators': 10}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books Model \n",
    "features 50  ngram 1,1 stopwords english depth 22 estimators 10\n",
    "cross val .928 test .917\n",
    "#### Space Model \n",
    "features 100, ngram 1,1 stopwords english, depth 20 estimators 14\n",
    "\n",
    "cross val .901 test 896\n",
    "\n",
    "#### Parties\n",
    "features 300 ngram 1,2 stopwords none, depth 22l estimators 14\n",
    "\n",
    "cross val .703 test .706\n",
    "\n",
    "#### Random\n",
    "cross val .520 . test .452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb_params = {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' :  [4000, 4500, 5000],\n",
    "    'cvec__ngram_range'  : [(1, 1), (1,2)],\n",
    "    'nb__alpha'          : [.4,.5,.6]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9578820697954272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('nb',   nb)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe3, param_grid= nb_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960431654676259"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 4500,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'nb__alpha': 0.5}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books \n",
    "model features 4500, ngram 1,2 , stopwords english\n",
    "\n",
    "cross val .958 test .960\n",
    "#### Space model\n",
    "features 3300, ngram 1,1 stopwords none alpha .3\n",
    "\n",
    "cross val .902 test .899\n",
    "#### Parties\n",
    "features 4500 ngram 1,1 stopwords english alpha .7\n",
    "\n",
    "cross val.690 test .678\n",
    "\n",
    "#### Random\n",
    "cross val .492 test .532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' : [500,700, 900],\n",
    "    'cvec__ngram_range'  : [(1, 1), (1,2)],\n",
    "    'knn__n_neighbors'   : [3,5,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8531889290012034\n"
     ]
    }
   ],
   "source": [
    "pipe4 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('knn',   knn)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe4, param_grid= knn_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028776978417267"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 700,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'knn__n_neighbors': 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books \n",
    " max features 100, ngram 1,1, stopwords english, knn =5\n",
    " \n",
    "cross val .856  test group.878 \n",
    "\n",
    "#### Space \n",
    "feature max features 700, ngram 1,1 stopwords english, knn =3 \n",
    "\n",
    "cross val .820 test .808\n",
    "\n",
    "#### Parties\n",
    "features 500 ngram 1,2 stopwords english, knn = 5\n",
    "\n",
    "cross val .637 Test .612\n",
    "\n",
    "#### Random\n",
    "cross val .523 test .517\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_params = {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' : [ 700, 900, 1100],\n",
    "    'cvec__ngram_range'  : [(1, 1), (1,2)],\n",
    "    'lr__penalty'        : ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446450060168472\n"
     ]
    }
   ],
   "source": [
    "pipe5 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('lr',   lr)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe5, param_grid= lr_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9496402877697842"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1100,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'lr__penalty': 'l1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books \n",
    "features 300, ngram 1,2 stopwords english, lr penalty l1\n",
    "\n",
    "cross val .946, test .950 accuracy\n",
    "\n",
    "#### Space \n",
    "features 500 ngram 1,1 stopwords english lr penalty l2\n",
    "\n",
    "crossval .905, test .908\n",
    "\n",
    "#### Parties\n",
    "features 900 ngram 1,1 stopwords none penalty l2\n",
    "\n",
    "crossval .707, test.723\n",
    "\n",
    "#### Random\n",
    "crossval .500 test .503\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, linear_model, datasets\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_m = svm.SVC() \n",
    "sv_m_params =  {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' : [ 2500, 3000],\n",
    "    'cvec__ngram_range'  : [(1, 1), (1,2)],\n",
    "    \"sv_m__C\"            : [.05,.1,.3 ],\n",
    "    \"sv_m__kernel\"       : ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253910950661853\n"
     ]
    }
   ],
   "source": [
    "pipe6 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('sv_m',   sv_m)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe6, param_grid= sv_m_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460431654676259"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2500,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'sv_m__C': 0.3,\n",
       " 'sv_m__kernel': 'linear'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books \n",
    "features 700, ngram 1,1 stopwords english c = .5 linear\n",
    "\n",
    "cross val .925 test .950\n",
    "\n",
    "#### Space \n",
    "features 100 ngram 1,2 stopwords english, c .5 linear\n",
    "\n",
    "cross val .897, test .888\n",
    "\n",
    "#### Parties\n",
    "features 2500 ngram 1,2 stopwords none c .1 linear\n",
    "\n",
    "cross val .729  test .707\n",
    "\n",
    "#### Random\n",
    "Cross val .504 test .503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada_params = {\n",
    "    'cvec__stop_words'   : ['english', None], \n",
    "    'cvec__max_features' : [100,300,500],\n",
    "    'cvec__ngram_range'  : [(1, 1)],\n",
    "    'ada__n_estimators'  : [50,60, 85 ],\n",
    "    'ada__learning_rate' : [.3, .4, .5],\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9554753309265944\n"
     ]
    }
   ],
   "source": [
    "pipe7 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('ada',   ada)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe7, param_grid= ada_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 0.4,\n",
       " 'ada__n_estimators': 60,\n",
       " 'cvec__max_features': 300,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460431654676259"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Books \n",
    "features 1000, ngram 1,1 stopwords none, learning rate .8 nestimators 50\n",
    "\n",
    "crossval .954, test .935\n",
    "\n",
    "#### Space \n",
    "feature 500 ngram 1,1 stopwords english learning rate .4 estmators 85\n",
    "\n",
    "crossval .911 test .929\n",
    "\n",
    "#### Parties\n",
    "features 300 ngram 1,1 stopwords none learning rate .4 estimators 60\n",
    "\n",
    "cross val .690 test .685\n",
    "\n",
    "#### Random \n",
    "cross val .513 test .484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
